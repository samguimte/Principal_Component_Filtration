{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\opensoundscape\\ml\\cnn.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# Loading necessary libraries\n",
    "\n",
    "\n",
    "import opensoundscape\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import librosa\n",
    "import torch\n",
    "import random\n",
    "import sys\n",
    "from PIL import Image\n",
    "from scipy.ndimage import median_filter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image as im \n",
    "from pathlib import Path\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "\n",
    "annotations = pd.read_csv(\"../raw_sonobuoy_images/modified_annotations.csv\")\n",
    "\n",
    "unique_annotation = annotations.drop_duplicates(subset=['spectrogram_path'])\n",
    "\n",
    "annotations_modded = annotations.copy()\n",
    "\n",
    "annotations_modded[\"spectrogram_path\"] = annotations[\"spectrogram_path\"].str.replace('raw_sonobuoy_images', 'processed_sonobuoy_images', regex=False)\n",
    "\n",
    "annotations_modded.to_csv(\"../processed_sonobuoy_images/modified_annotations.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram_path</th>\n",
       "      <th>label</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../raw_sonobuoy_images/CC0407-SB10-040717-2222...</td>\n",
       "      <td>D</td>\n",
       "      <td>406</td>\n",
       "      <td>83</td>\n",
       "      <td>447</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../raw_sonobuoy_images/CC0407-SB10-040717-2222...</td>\n",
       "      <td>D</td>\n",
       "      <td>106</td>\n",
       "      <td>83</td>\n",
       "      <td>146</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../raw_sonobuoy_images/CC0407-SB17-040719-2050...</td>\n",
       "      <td>D</td>\n",
       "      <td>431</td>\n",
       "      <td>67</td>\n",
       "      <td>471</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../raw_sonobuoy_images/CC0407-SB17-040719-2050...</td>\n",
       "      <td>D</td>\n",
       "      <td>131</td>\n",
       "      <td>67</td>\n",
       "      <td>171</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../raw_sonobuoy_images/CC0407-SB2-040713-23500...</td>\n",
       "      <td>D</td>\n",
       "      <td>338</td>\n",
       "      <td>77</td>\n",
       "      <td>372</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    spectrogram_path label  xmin  ymin  xmax  \\\n",
       "0  ../raw_sonobuoy_images/CC0407-SB10-040717-2222...     D   406    83   447   \n",
       "1  ../raw_sonobuoy_images/CC0407-SB10-040717-2222...     D   106    83   146   \n",
       "2  ../raw_sonobuoy_images/CC0407-SB17-040719-2050...     D   431    67   471   \n",
       "3  ../raw_sonobuoy_images/CC0407-SB17-040719-2050...     D   131    67   171   \n",
       "4  ../raw_sonobuoy_images/CC0407-SB2-040713-23500...     D   338    77   372   \n",
       "\n",
       "   ymax  \n",
       "0   123  \n",
       "1   123  \n",
       "2   123  \n",
       "3   123  \n",
       "4   129  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining draw image functions\n",
    "\n",
    "def draw_img(ax, img_vector, h=141, w=601):\n",
    "    \"\"\"\n",
    "    1. takes img_vector,\n",
    "    2. reshapes into right dimensions,\n",
    "    3. draws the resulting image\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ax.imshow( (img_vector).reshape(h,w), cmap=plt.cm.gray)\n",
    "    \n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "def draw_img_single(img_vector, h=141, w=601):\n",
    "    \"\"\"\n",
    "    1. takes img_vector,\n",
    "    2. reshapes into right dimensions,\n",
    "    3. draws the resulting image\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    plt.imshow( (img_vector).reshape(h,w), cmap=plt.cm.gray)\n",
    "    \n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we construct the matrix of image data (rows are spectrograms and columns are pixel values for each spectrogram)\n",
    "\n",
    "data_matrix = []\n",
    "\n",
    "for index, row in unique_annotation.iterrows():\n",
    "\n",
    "    image = Image.open(row['spectrogram_path'])\n",
    "\n",
    "    pixel_values = np.array(list(image.getdata()))\n",
    "\n",
    "    data_matrix.append(pixel_values)\n",
    "\n",
    "stacked_specs = np.vstack(data_matrix)\n",
    "\n",
    "\n",
    "scaler = StandardScaler(with_std=False)\n",
    "data_matrix_mod1 = scaler.fit_transform(stacked_specs)\n",
    "original_data = data_matrix_mod1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Singular Value Decomposition\n",
    "\n",
    "\n",
    "# U is the eigenbasis of the original space (eigen vectors span directions of maximal variance)\n",
    "\n",
    "# S is the diagonal matrix of singular values of \"original_data\" that determine the extent to which the eigen axes are stretched to create the original features; these are the square roots of the eigenvalues for the covariance matrix of the data\n",
    "\n",
    "# T is the transpose of the matrix whose columns represent the principal components of \"original_data\" (these columns are the orthonormal basis vectors of the transformed space that point in the directions of maximal variance)\n",
    "\n",
    "U, S, T = np.linalg.svd(original_data, full_matrices=False)\n",
    "\n",
    "US = U*S\n",
    "\n",
    "svd_data = US @ T\n",
    "\n",
    "svd_data_scaled = scaler.inverse_transform(svd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the cell with commented code on plotting all these spectrograms :3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 342) (342,) (342, 84741)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#fig, axs = plt.subplots(100, 2, figsize = (30, 200))\n",
    "\n",
    "#for idx, ax in enumerate(axs.flat):\n",
    "    \n",
    "#    draw_img(ax, matrix[idx])\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function defined below takes in a data matrix and certain arguments that specify the extent to which it will execute principal component denoising.\n",
    "Maybe it would be wise to implement a version of this function that derives the height and width parameters automatically.... Just something to think about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_column_sub(data, feature_percentile = 50, observation_percentile = 50, num_components = 3, variance_explained = None, height = 141, width = 601):\n",
    "\n",
    "    # Using Singular Value Decomposition to generate the principle eigenvectors\n",
    "\n",
    "    U, S, T = np.linalg.svd(data, full_matrices=False)\n",
    "\n",
    "    US = U*S\n",
    "\n",
    "    # Filtering the specified number of principal components\n",
    "    \n",
    "    # First check if user wants to specify the number of components or if they will opt to calculate the number of components based on a variance threshold\n",
    "\n",
    "    if variance_explained == None:\n",
    "\n",
    "        # Creating a matrix to contain the pixel magnitude adjusted principal components\n",
    "\n",
    "        signal_enhanced_features = np.zeros_like(T[0:num_components,:])\n",
    "\n",
    "\n",
    "        # Now let i be the number of rows in the new Principal Component matrix to iterate through each \"eigen - signal\"\n",
    "\n",
    "        for i in range(len(signal_enhanced_features)):\n",
    "            \n",
    "            # pick out the ith \"eigen - signal\" as a 2d spectrogram matrix\n",
    "\n",
    "            feature = np.copy(T[i].reshape((height, width)))\n",
    "\n",
    "            # Let j be the number of columns in the feature and iterate through every column, extract the user-specified percentile value and subtract this value from the whole column vector; move on to the next column, extract percentile value, subtract, iterate and repeat;\n",
    "            # note that we set all values that become negative as a result to 0 automatically\n",
    "\n",
    "            for j in range(feature.shape[1]):\n",
    "                column = feature[:, j]\n",
    "                percentile_value = np.percentile(column, feature_percentile)\n",
    "                feature[:, j] = column - percentile_value\n",
    "                feature[:, j][feature[:, j] < 0] = 0\n",
    "\n",
    "            # Store this noise - adjusted \"eigen - signal\" in the new \"Principal Component\" matrix\n",
    "\n",
    "            signal_enhanced_features[i] = feature.flatten()\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Using the user's threshold for variance explained in the data, we need to calculate how many components will be kept during the PCA algorithm\n",
    "\n",
    "        \n",
    "        # First create a new whose values correspond to the variance explained for each singular value then create another vector whose entries are the ordered cumulative sum (until ~1) of those variance values\n",
    "\n",
    "        # Then just add 1 to the index of the entry in this vector whose value is at least that of the user-defined threshold\n",
    "        \n",
    "        variance_individual = (S ** 2) / np.sum(S ** 2)\n",
    "\n",
    "        cumulative_variance = np.cumsum(variance_individual)\n",
    "\n",
    "        num_components = np.argmax(cumulative_variance >= variance_explained) + 1\n",
    "        \n",
    "\n",
    "\n",
    "        # Same code as above in the \"if\" block just using the new number of components\n",
    "\n",
    "        signal_enhanced_features = np.zeros_like(T[0:num_components,:])\n",
    "\n",
    "        for i in range(len(signal_enhanced_features)):\n",
    "\n",
    "            feature = np.copy(T[i].reshape((height, width)))\n",
    "\n",
    "            for j in range(feature.shape[1]):\n",
    "                column = feature[:, j]\n",
    "                percentile_value = np.percentile(column, feature_percentile)\n",
    "                feature[:, j] = column - percentile_value\n",
    "                feature[:, j][feature[:, j] < 0] = 0\n",
    "\n",
    "            signal_enhanced_features[i] = feature.flatten()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Finally, we reconstruct the data matrix with our observations using the filtered components and the mixing matrix US\n",
    "\n",
    "    reconstruction = US[:, 0:num_components] @ signal_enhanced_features[0:num_components, :]\n",
    "\n",
    "\n",
    "    return reconstruction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
